# Research Agent Guide & Best Practices üß†

Esta gu√≠a explica c√≥mo funciona el **Research Agent** actual de Briefly y propone una hoja de ruta de mejoras basada en las mejores pr√°cticas de la industria para agentes aut√≥nomos en 2024.

---

## 1. ¬øC√≥mo funciona el Agente Actual?

El agente actual (`backend/app/agents/research_agent.py`) sigue un patr√≥n **"Plan-then-Act" lineal**. Es efectivo para tareas simples pero tiene limitaciones para investigaciones complejas.

### Flujo de Ejecuci√≥n (Pipeline Lineal)

1.  **Planificaci√≥n (Heur√≠stica)**:
    *   Recibe un `topic`.
    """
    Agent that performs deep research to find news sources for a topic.
    Designed for streaming output of its thought process.
    Implements ReAct pattern with Validation Step.
    """
    *   *Limitaci√≥n: No usa un LLM para "pensar" creativamente sobre qu√© buscar, solo llena huecos.*

2.  **B√∫squeda (Search)**:
    *   Ejecuta las queries en Google/Tavily.
    *   Agrega resultados a una lista de candidatos, eliminando duplicados por dominio.
    *   *Limitaci√≥n: No eval√∫a la calidad del resultado antes de abrirlo, solo conf√≠a en el t√≠tulo.*

3.  **Validaci√≥n y Filtrado (Filter)**:
    *   Toma los primeros 8 candidatos.
    *   Intenta scrapear 3 art√≠culos de la home de cada uno.
    *   Si encuentra art√≠culos -> **V√°lido**. Si no -> **Descartado**.
    *   *Limitaci√≥n: Si el sitio tiene un anti-bot fuerte o estructura compleja, se descarta aunque sea una fuente excelente.*

4.  **Resultado**:
    *   Devuelve la lista de fuentes validadas.

---

## 2. Mejores Pr√°cticas en la Industria (2024)

Basado en la investigaci√≥n de arquitecturas de agentes aut√≥nomos (AutoGPT, BabyAGI, LangChain):

### A. Patrones de Razonamiento
*   **ReAct (Reason + Act)**: En lugar de un plan fijo, el agente deber√≠a:
    1.  **Pensar**: "¬øQu√© informaci√≥n me falta para completar este briefing?"
    2.  **Actuar**: Ejecutar una herramienta (buscar, leer, navegar).
    3.  **Observar**: Analizar el resultado.
    4.  **Repetir**: Decidir el siguiente paso basado en la observaci√≥n.
*   **Reflection**: El agente debe criticar su propio trabajo. "¬øEsta fuente es realmente fiable o es clickbait? ¬øNecesito buscar una segunda opini√≥n?"

### B. Uso de Herramientas (Tool Use)
El agente no deber√≠a ser solo un script. Deber√≠a tener acceso a una "caja de herramientas":
*   `search_web(query)`
*   `read_page(url)`
*   `check_rss_feed(url)`
*   `validate_credibility(text)`

### D. Tendencias 2025 (The Agentic Era)
*   **Multi-Agent Systems (MAS)**: La colaboraci√≥n entre agentes especializados es el est√°ndar. Un "Manager Agent" orquesta a agentes investigadores, escritores y validadores.
*   **Agentic Mesh**: Arquitectura distribuida y modular donde los agentes son peque√±os, especializados y se comunican entre s√≠.
*   **Explainable AI (XAI)**: Los agentes deben explicar *por qu√©* tomaron una decisi√≥n (ej: "¬øPor qu√© descartaste esta fuente?").
*   **Human-in-the-Loop**: Para decisiones cr√≠ticas, el agente propone y el humano aprueba.
*   **LLM-as-a-Judge**: Usar un LLM potente (ej: GPT-4o, Claude 3.5 Sonnet) para evaluar la calidad del output de agentes m√°s peque√±os y r√°pidos.

---

## 3. Propuesta de Mejoras (Roadmap)

### Nivel 1: Optimizaciones Inmediatas (Quick Wins) ‚ö°
1.  **Generaci√≥n de Queries con LLM**:
    *   Reemplazar la lista fija de f-strings por una llamada a Gemini/Claude.
    *   *Prompt*: "Genera 3 queries de b√∫squeda avanzadas para encontrar fuentes de noticias profundas sobre '{topic}'. Evita sitios gen√©ricos."
2.  **Validaci√≥n de Frecuencia y Relevancia**:
    *   **Frecuencia**: Verificar que la fuente tenga al menos **1-2 art√≠culos por mes** en los √∫ltimos 3 meses. Esto asegura que la fuente est√© activa.
    *   **Relevancia (Post-Research)**: Al finalizar, usar un LLM para leer los t√≠tulos/res√∫menes scrapeados y asignar un **Relevance Score (1-10)** respecto al topic original. Filtrar fuentes con score < 7.
3.  **Detecci√≥n de RSS**:
    *   Muchos sitios de noticias tienen feeds RSS ocultos. Detectarlos garantiza actualizaciones m√°s fiables que el scraping visual.

### Nivel 2: Arquitectura Ag√©ntica (Medium Term) üõ†Ô∏è
4.  **Implementar Patr√≥n ReAct**:
    *   Permitir que el agente decida si necesita m√°s b√∫squedas. "Encontr√© 2 fuentes, pero el usuario pidi√≥ 5. Voy a buscar t√©rminos relacionados."
5.  **Parallelization**:
    *   La validaci√≥n actual es secuencial (lenta). Usar `asyncio.gather` para validar 5 sitios en paralelo.

### Nivel 3: Agente Aut√≥nomo Avanzado (Long Term) üöÄ
6.  **Reflection Step**:
    *   Antes de entregar el briefing, el agente hace un loop de auto-cr√≠tica: "He seleccionado estas 5 fuentes. ¬øSon demasiado similares? ¬øHay sesgo? Voy a reemplazar una por una fuente de opini√≥n contraria."
7.  **Memory System (PostgreSQL)**:
    *   Crear una tabla `SourceReputation`. Si el agente valida "The Veritas" hoy, guardarlo como fuente confiable globalmente para futuras b√∫squedas.

---

## 4. Ejemplo de Flujo Mejorado (Nivel 2)

```mermaid
graph TD
    A[Input: "Crypto Trends"] --> B{LLM: Plan Queries}
    B --> C[Query 1: "Top crypto news sites"]
    B --> D[Query 2: "DeFi analysis blogs"]
    C & D --> E[Search Tools (Parallel)]
    E --> F[Raw Candidates List]
    F --> G{LLM Filter: Are these relevant?}
    G -- Yes --> H[Scraper Agents (Parallel)]
    G -- No --> I[Discard]
    H --> J{Quality Check: Good content?}
    J -- Good --> K[Add to Briefing]
    J -- Bad --> L[Discard]
    K --> M[Final Briefing]
```
